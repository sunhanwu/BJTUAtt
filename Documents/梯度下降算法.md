# 梯度下降算法
@(机器学习)[机器学习, 算法]

将代价函数J最小化，用于线性回归等机器学习领域的求最小化代价函数
代价函数：$J(\theta_0,\theta_1)$
```flow
st=>start: Start
op1=>operation: 选择一些合适的参数
op2=>operation: 一直改变参数的值，让代价函数减小
en=>end: 找到局部最小值

st->op1->op2->en
```
梯度下降算法会由于起点的不同得到不同的局部最优解
$$\theta_j:=\theta_j-\alpha\frac{\partial }{\partial_{\theta_j}}J(\theta_0,\theta_1)$$
+ 注意这里的：=j就是赋值
+ $\alpha$是学习速率
$temp0:=\theta_0-\alpha\frac{\partial }{\partial_{\theta_0}}J(\theta_0,\theta_1)$
$temp1:=\theta_1-\alpha\frac{\partial }{\partial_{\theta_1}}J(\theta_0,\theta_1)$
$\theta_0:=temp0$
$\theta_1:=temp1$